{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Intro\n",
    "\n",
    "환경은 구글 Colab을 사용하였습니다.\n",
    "메인이 되는 트레이닝 방식은 Semi-supervised 입니다.\n",
    "\n",
    "## Flow\n",
    "\n",
    "제가 대회에 참여하면서 생각하고 진행했던 내용 입니다.\n",
    "\n",
    "- CNN 모델링을 하면서 성능이 제일 잘 나오는 모델을 먼저 찾아보았습니다.\n",
    "- CNN은 Skip Connection 과 CBAM(발음주의)이라는 CNN Attention 기법을 섞어서 만들었습니다. \n",
    "    - Skip Connection을 가장 먼저 시도하였고 그 후 CBAM을 연결하였습니다.\n",
    "- 0.88 정도가 나오는 단일 모델을 찾은 후, Semi-supervised를 진행하였습니다.\n",
    "    - 진행순서는 다음과 같습니다.\n",
    "    - [1] 가장 validation이 잘 나오는 모델로 test를 예측합니다.\n",
    "    - [2] 예측한 test중 label을 95% 이상이라고 예측한것만 추가로 test의 label로 넣어줍니다.\n",
    "    - [3] train과 test를 합쳐서 다시 훈련합니다. (validation set은 test와 합치기 전 맨처음 split해놓은 상태로 오로지 validation만 합니다.)\n",
    "    - [4] 1~3번을 10번 반복하여 나온 결과를 저장합니다.\n",
    "- train data(전체) 와 예측된 test를 가지고 5fold 훈련을 하고 정답을 예측합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ymeJmzsCFLn"
   },
   "outputs": [],
   "source": [
    "path = \"/content/drive/My Drive/data/dacon mnist/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z79wq2DMG5ey"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ytg7hPSmVo2n",
    "outputId": "abd3a03c-6536-4cf1-db21-0c9d6d30995b"
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cpu'\n",
    "if cuda.device_count() > 0:\n",
    "    device = 'cuda'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJoKdZRkHETB"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(path + \"train.csv\")\n",
    "test = pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFi3t8wcmZHI"
   },
   "outputs": [],
   "source": [
    "test['digit'] = np.nan\n",
    "test = pd.concat([test.iloc[:, :2], test.iloc[:, -1], test.iloc[:, 2:-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DHmyEsrOkey"
   },
   "outputs": [],
   "source": [
    "from string import ascii_uppercase\n",
    "chars = {abc: i for i, abc, in enumerate(ascii_uppercase)}\n",
    "data['letter'] = data['letter'].map(chars)\n",
    "test['letter'] = test['letter'].map(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIzUge3wHMIV"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Attention(CBAM) \n",
    "위에서 언급했던 CNN의 Attention 기법입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUXPgjZ51ZUJ"
   },
   "outputs": [],
   "source": [
    "# https://github.com/Jongchan/attention-module\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = torch.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = torch.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip Connection을 사용한 CNN 및 CBAM적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DpjGUEsAoa1"
   },
   "outputs": [],
   "source": [
    "#  # 0.8878048780487805\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()                \n",
    "        self.first = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(1, 128, kernel_size=5, stride=1, padding=5//2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )        \n",
    "        self.conv1 = self.main_block(128, 256)        \n",
    "        self.skip1 = self.skip_block(128, 256)\n",
    "        self.conv2 = self.main_block(256, 512)\n",
    "        self.skip2 = self.skip_block(256, 512)\n",
    "        self.conv_cbam1 = CBAM(256, reduction_ratio=16)\n",
    "        self.skip_cbam1 = CBAM(256, reduction_ratio=16)\n",
    "        self.conv_cbam2 = CBAM(512, reduction_ratio=16)\n",
    "        self.skip_cbam2 = CBAM(512, reduction_ratio=16)\n",
    "\n",
    "        self.fc = nn.Sequential(            \n",
    "            nn.BatchNorm1d(8192),\n",
    "            nn.Linear(8192, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 10),          \n",
    "        )\n",
    "        \n",
    "\n",
    "    def main_block(self, in_feature, out_feature):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm2d(in_feature),\n",
    "            nn.Conv2d(in_feature, in_feature, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(in_feature),\n",
    "            nn.Conv2d(in_feature, out_feature, kernel_size=3, stride=1, padding=3//2),\n",
    "        )\n",
    "    def skip_block(self, in_feature, out_feature):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm2d(in_feature),\n",
    "            nn.Conv2d(in_feature, out_feature, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.first(x)\n",
    "        conv1 = self.conv1(x)\n",
    "        conv1 = self.conv_cbam1(conv1)\n",
    "        skip1 = self.skip1(x)        \n",
    "        skip1 = self.skip_cbam1(skip1)\n",
    "        x = F.relu(conv1 + skip1)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        conv2 = self.conv2(x)\n",
    "        conv2 = self.conv_cbam2(conv2)\n",
    "        skip2 = self.skip2(x)\n",
    "        skip2 = self.skip_cbam2(skip2)\n",
    "        x = F.relu(conv2 + skip2)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        out = self.fc(x.view(batch_size, -1))        \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "C3NYfbkBvVwt",
    "outputId": "638d4856-f499-41b3-c83b-f78e3a742adc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "summary(model, (1, 32, 32), batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJeQ6v4jLiRp"
   },
   "outputs": [],
   "source": [
    "class ImageData(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.image = np.expand_dims(df.iloc[:, 3:].values.reshape(-1, 28, 28), axis=3)\n",
    "        self.labels = df['digit'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index].astype(np.int)           \n",
    "        image = self.transform(self.image[index].astype(np.uint8))\n",
    "        #image = torch.Tensor(image).unsqueeze(0)\n",
    "        return image, label\n",
    "\n",
    "class TestImageData(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.image = np.expand_dims(df.iloc[:, 3:].values.reshape(-1, 28, 28), axis=3)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.image[index]\n",
    "        image = self.transform(self.image[index].astype(np.uint8))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oYBrU2l_4KH5"
   },
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data, test_size=0.1, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "\n",
    "augmentation은 \n",
    "\n",
    "1. 이미지 패딩을 5를 준 상태에서 Random Crop을 하여 \n",
    "\n",
    "   최대한 원본 이미지의 손상이 없는 상태에서 이미지의 이동이 일어나게 하였습니다.\n",
    "\n",
    "2. Affine 변환\n",
    "\n",
    "3. Random Erasing\n",
    "\n",
    "3가지를 랜덤하게 적용하도록 하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErDwqQwsLue4"
   },
   "outputs": [],
   "source": [
    "# transforms.Normalize(0.1430, 0.2538)\n",
    "randomApply = transforms.RandomApply([transforms.RandomAffine(30)])\n",
    "data_transf = transforms.Compose([\n",
    "                                  transforms.ToPILImage(), \n",
    "                                  transforms.Resize((32,32)), \n",
    "                                  transforms.RandomApply([transforms.RandomCrop(size=(32,32), padding=5)]),\n",
    "                                  randomApply, transforms.ToTensor(),                                   \n",
    "                                  transforms.Normalize(0.5, 0.5),\n",
    "                                  transforms.RandomErasing(),\n",
    "                                  ])\n",
    "test_transf = transforms.Compose([transforms.ToPILImage(), transforms.Resize((32,32)), transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])\n",
    "\n",
    "train_data = ImageData(df = train, transform = data_transf)\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = 64, shuffle=True)\n",
    "valid_data = ImageData(df = valid, transform = test_transf)\n",
    "valid_loader = DataLoader(dataset = valid_data, batch_size = 512)\n",
    "test_data = TestImageData(df = test, transform = test_transf)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyi3MpgNxNor"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader):\n",
    "    EPOCH = 100\n",
    "    best_model = None\n",
    "    best_loss = 9876543210\n",
    "    best_acc = 0\n",
    "    early_stop_patience = 0\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = model.to(device)    \n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        print('='*20 + f' EPOCH - {epoch} ' + '='*20)\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for image, label in train_loader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(image)\n",
    "            loss = criterion(pred, label)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print(f'train_loss : {train_loss / len(train_loader)}')\n",
    "        # validation\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        preds = []\n",
    "        labels = []\n",
    "        for image, label in valid_loader:\n",
    "            with torch.no_grad():\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                pred = model(image)\n",
    "                loss = criterion(pred, label)\n",
    "                valid_loss += loss.item()  \n",
    "                preds.extend(F.softmax(pred.to('cpu'), dim=1).argmax(dim=1).tolist())\n",
    "                labels.extend(label.to('cpu').tolist())\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        valid_loss /= len(valid_loader)\n",
    "        scheduler.step(valid_loss)\n",
    "    \n",
    "        early_stop_patience += 1\n",
    "        print(f'valid_loss: {valid_loss}, valid_acc: {acc}')\n",
    "        if epoch % 10 == 0:\n",
    "            print(confusion_matrix(labels, preds))\n",
    "        if best_loss > valid_loss and best_acc <= acc:\n",
    "            best_loss = valid_loss                \n",
    "            best_acc = acc\n",
    "            best_model = model.state_dict()\n",
    "            print(f'model_saved, best_acc : {acc}')\n",
    "        #     early_stop_patience = 0\n",
    "        # if early_stop_patience > 10:\n",
    "        #     break\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xKJUhavEhBrp"
   },
   "outputs": [],
   "source": [
    "def infer_newdata(model, test_data, test_transf):\n",
    "    preds = []\n",
    "    test_dataset = TestImageData(test_data, test_transf)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=512)\n",
    "    model.eval()\n",
    "    for image in test_loader:\n",
    "        with torch.no_grad():\n",
    "            image = image.to(device)\n",
    "            pred = model(image)\n",
    "            pred = F.softmax(pred.to('cpu'), dim=1).numpy()\n",
    "            preds.append(pred)\n",
    "    preds = np.concatenate(preds)\n",
    "    idx = np.argwhere(preds>0.95)\n",
    "    test_data.loc[idx[:, 0], 'digit'] = idx[:,1]\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_USKDt890Xk-",
    "outputId": "449c2fee-5646-4b6b-d717-bc239857644f"
   },
   "outputs": [],
   "source": [
    "for n_semi in range(10):\n",
    "    best_model = train_model(model, train_loader, valid_loader)\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    test = infer_newdata(model, test, test_transf)\n",
    "    new_data = pd.concat([train, test.dropna()], axis=0)\n",
    "    new_dataset = ImageData(new_data, data_transf)\n",
    "    train_loader = DataLoader(new_dataset, batch_size=64, shuffle=True)\n",
    "    print('='*20 + f' SEMI SUPERVISED START - {n_semi} ' + '='*20)\n",
    "    print(f'new train dataset - train: {len(train)} + new: {len(test.dropna())} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RE-training 및 Inference\n",
    "training 시간이 길어 중간 결과를 저장한 후 이를 이용하여 재훈련시켰습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTQKpTi8OzS8"
   },
   "outputs": [],
   "source": [
    "test.to_csv(path+'10semi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCXqXBJUa90T"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(path + '10semi.csv')\n",
    "new_data = pd.concat([data, test.dropna()], axis=0, ignore_index=True)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9ZoYO58Rd7do",
    "outputId": "06a29506-58bd-49a9-aaf7-f362d1bacde7"
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for train_idx, valid_idx in kfold.split(new_data):\n",
    "    model = ConvNet()\n",
    "    train = new_data.iloc[train_idx]\n",
    "    valid = new_data.iloc[valid_idx]\n",
    "    train_data = ImageData(df = train, transform = data_transf)\n",
    "    train_loader = DataLoader(dataset = train_data, batch_size = 64)\n",
    "    valid_data = ImageData(df = valid, transform = test_transf)\n",
    "    valid_loader = DataLoader(dataset = valid_data, batch_size = 512)\n",
    "    best = train_model(model, train_loader, valid_loader)\n",
    "    models.append(best)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UBBanvjfpZc"
   },
   "outputs": [],
   "source": [
    "# inference 5fold\n",
    "total = []\n",
    "for state in models:\n",
    "    model = ConvNet()\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    for image in test_loader:    \n",
    "        with torch.no_grad():\n",
    "            image = image.to(device)\n",
    "            pred = model(image)\n",
    "            preds.extend(F.softmax(pred.to('cpu'), dim=1).tolist())\n",
    "    total.append(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgcBtEvfGFvG"
   },
   "outputs": [],
   "source": [
    "total = np.array(total).mean(axis=0)\n",
    "total = total.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PsFfn4l4rgE7"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(path + 'submission.csv')\n",
    "\n",
    "submission['digit'] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljQSOeegQ9RS"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path+'20200903_5fold_semi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVCYKXKpG-W1"
   },
   "source": [
    "# 6. etc.\n",
    "\n",
    "뒤늦게 참가해서 Toy프로젝트 하는 느낌으로 참가했는데 우연찮게 올라오게 되었습니다.\n",
    "\n",
    "이럴 줄 알았으면 코드를 좀 깔끔하게 하는건데. 다음부터는 항상 예쁘게 짜야겠다는 생각이 듭니다.\n",
    "\n",
    "위 코드에는 제가 의도하지않은 몇가지 오류가 있는데요, 수정하여 코드를 작성한것도 있으나\n",
    "\n",
    "당시 제출에 사용했던것과 가장 근접한 코드가 남은것이 이 코드라 그대로 올리게 되었습니다.\n",
    "\n",
    "1. Semi training 시 모델을 새로 생성하지 않고 기존것을 이어서 훈련하고있습니다.\n",
    "2. 한번 저장한 것을 load하면서 재훈련 하다보니 코드가 수정되어 조금 다른 결과가 나올수 있습니다.\n",
    "3. seed설정을 안한 부분이 있는데, 결과가 크게 달라지지 않을 것이라 생각하여 중요하게 생각하진 않았습니다.\n",
    "\n",
    "마지막에 tpu를 사용하는것으로 변환하면서 개선시키다보니 이전코드에 반영이 안되 아쉽네요.\n",
    "\n",
    "개선시킨다면, Semi-training 시작부터 10fold 훈련-예측을 사용하고\n",
    "이후에 inference 부분에서도 10fold 및 validationd을 기존 train 데이터에서만 뽑아 적용하는것이 더 낫지 않았나 싶습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "daicon mnist4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
