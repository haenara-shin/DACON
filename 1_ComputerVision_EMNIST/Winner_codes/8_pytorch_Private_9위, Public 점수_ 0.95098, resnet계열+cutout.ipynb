{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview  \n",
    "Model : resnext101_32x8d, wide_resnet101_2  \n",
    "Scheduler : MultiStepLR  \n",
    "Loss : CrossEntropyLoss  \n",
    "Optimizer : AdamW  \n",
    "Epoch : 300  \n",
    "batch size : 64  \n",
    "learning rate : 0.01  \n",
    "Data augmentation : Resize, ShiftScaleRotate, Ramdom size cutout  \n",
    "Esemble : 2 resnext101_32x8d + 1 wide_resnet101_2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 생성  \n",
    "데이터셋으로는 이미지, 영어벡터, digit number를 받았습니다  \n",
    "데이터는 train : val = 0.8 : 0.2 비율로 나놨습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "from model import *\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "class EMNIST(Dataset):\n",
    "    def __init__(self, transform = None, dir = 'data/train.csv', datatype = 'train', ratio = 0.8):\n",
    "        \n",
    "        dataset = pd.read_csv(dir)\n",
    "        num = int(len(dataset)*ratio)\n",
    "        \n",
    "        if datatype =='train':\n",
    "            dataset = dataset[:num]\n",
    "        elif datatype =='val':\n",
    "            dataset = dataset[num:]\n",
    "            \n",
    "        self.digit = dataset['digit'].values\n",
    "        self.letter = pd.get_dummies(dataset['letter']).values\n",
    "        self.img = dataset.iloc[:,3:].values.reshape(-1, 28, 28)/255.\n",
    "        self.transform = transform\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        image = self.img[index]\n",
    "        letter = torch.FloatTensor(self.letter[index]).unsqueeze(dim=0)\n",
    "        digit = self.digit[index]\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image) \n",
    "            image = augmented['image']\n",
    "        image = torch.FloatTensor(image).unsqueeze(dim=0)\n",
    "        sample = (image, letter, digit)\n",
    "        return sample\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "class EMNIST_test(Dataset):\n",
    "    def __init__(self, transform = None, dir = 'data/test.csv'):\n",
    "        \n",
    "        dataset = pd.read_csv(dir)\n",
    "\n",
    "        self.letter = pd.get_dummies(dataset['letter']).values\n",
    "        self.img = dataset.iloc[:,2:].values.reshape(-1, 28, 28)/255.\n",
    "        self.transform = transform\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        image = self.img[index]\n",
    "        letter = torch.FloatTensor(self.letter[index]).unsqueeze(dim=0)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image) \n",
    "            image = augmented['image']\n",
    "        image = torch.FloatTensor(image).unsqueeze(dim=0)\n",
    "        sample = (image, letter)\n",
    "        return sample\n",
    "    \n",
    "    \n",
    "albumentations_transform = albumentations.Compose([\n",
    "    albumentations.Resize(112, 112), \n",
    "    albumentations.augmentations.transforms.ShiftScaleRotate(),\n",
    "\n",
    "])\n",
    "\n",
    "albumentations_transform_val = albumentations.Compose([\n",
    "    albumentations.Resize(112, 112), \n",
    "\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "albumentations_transform_test = albumentations.Compose([\n",
    "    albumentations.Resize(112, 112), \n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "trainset = EMNIST(transform = albumentations_transform)\n",
    "testset = EMNIST(transform = albumentations_transform_val, datatype='val')\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,shuffle=True, drop_last=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model  \n",
    "model은 resnext101_32x8d와 wide_resnet101_2을 사용하였으며  \n",
    "영어 벡터정보도 함께 학습하여 prediction 값을 뽑도록 하였습니다.  \n",
    "github에 있는 resnet을 가져와서 수정하는 방식으로 코드를 작성하였습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=10, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.conv_letter = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(16, 64, 4, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 5, padding=2), nn.ReLU(),\n",
    "            nn.Conv1d(128, 64, 4, padding=2), nn.ReLU(),\n",
    "            nn.Conv1d(64, 16, 3), nn.ReLU(),\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(2432, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x,y):\n",
    "        bsz = x.size(0)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        out = self.layer4(x)\n",
    "        \n",
    "        out = F.avg_pool2d(out, out.size()[3],4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = torch.cat((self.conv_letter(y).view(bsz, -1), out), dim=1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x,letter):\n",
    "        return self._forward_impl(x,letter)\n",
    "\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resnext101_32x8d(pretrained=False, progress=True, **kwargs):\n",
    "\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 8\n",
    "    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n",
    "                   pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def wide_resnet101_2(pretrained=False, progress=False, **kwargs):\n",
    "\n",
    "    kwargs['width_per_group'] = 64 * 2\n",
    "    return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3],\n",
    "                   pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = wide_resnet101_2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 230, 265], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutout  \n",
    "0.25 ~ 0.5 랜덤한 비율로 이미지 일부를 삭제 하여 학습을 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(img,ratio,n_hole,device):\n",
    "    if len(img.size())==3:\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "        \n",
    "    elif len(img.size())==4:\n",
    "        h = img.size(2)\n",
    "        w = img.size(3)\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    mask = np.ones((h, w), np.float32)\n",
    "    \n",
    "    for _ in range(n_hole):\n",
    "        y = np.random.randint(h - h * ratio)\n",
    "        x = np.random.randint(w - w * ratio)\n",
    "\n",
    "        x1 = int(x + h * ratio)\n",
    "        y1 = int(y + w * ratio)\n",
    "        mask[y: y1, x: x1] = 0.\n",
    "            \n",
    "    mask = torch.from_numpy(mask).to(device)\n",
    "    img = img * mask\n",
    "\n",
    "\n",
    "    return img\n",
    "\n",
    "def Cutout(img,min_ratio, max_ratio, device):\n",
    "    for idx in range(img.size(0)):\n",
    "        ratio = (max_ratio - min_ratio)/(10)\n",
    "        ratio = min_ratio + ratio * random.randint(0,9)\n",
    "        img[idx] = cutout(img[idx],ratio,1,device)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct_digit = 0\n",
    "    correct_letter = 0\n",
    "    total = 0\n",
    "\n",
    "    \n",
    "    for batch_idx, batch in enumerate(trainloader):\n",
    "        inputs = batch[0]\n",
    "        l_letter = batch[1]\n",
    "        l_digit = batch[2]\n",
    "        \n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        l_digit = l_digit.to(device, dtype=torch.long)\n",
    "        l_letter = l_letter.to(device, dtype=torch.float)\n",
    "        inputs = Cutout(inputs, 0,0.5, device)\n",
    "        optimizer.zero_grad()\n",
    "        out_digit = net(inputs, l_letter)\n",
    "        loss = criterion(out_digit, l_digit)\n",
    "\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, pred_digit = out_digit.max(1)\n",
    "\n",
    "        total += l_digit.size(0)\n",
    "        correct_digit += pred_digit.eq(l_digit).sum().item()\n",
    "    scheduler.step()\n",
    "    if epoch%10 ==0:\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "        print(batch_idx,'/', len(trainloader), ' Loss: %.3f | Acc: %.3f%% (%d/%d)  '\n",
    "                % (train_loss/(batch_idx+1), 100.*correct_digit/total, correct_digit, total))\n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "def test(net, epoch):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct_digit = 0\n",
    "    correct_letter = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(testloader):\n",
    "            inputs = batch[0]\n",
    "            l_letter = batch[1]\n",
    "            l_digit = batch[2]\n",
    "            \n",
    "            \n",
    "\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            l_digit = l_digit.to(device, dtype=torch.long)\n",
    "            l_letter = l_letter.to(device, dtype=torch.float)\n",
    "            \n",
    "            \n",
    "            out_digit = net(inputs, l_letter)\n",
    "            loss = criterion(out_digit, l_digit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, pred_digit = out_digit.max(1)\n",
    "\n",
    "            total += l_digit.size(0)\n",
    "            correct_digit += pred_digit.eq(l_digit).sum().item()\n",
    "        if epoch%10 ==0:\n",
    "            print(batch_idx,'/', len(testloader), ' Loss: %.3f | Acc: %.3f%% (%d/%d) '\n",
    "                    % (test_loss/(batch_idx+1), 100.*correct_digit/total, correct_digit, total, ))\n",
    "            \n",
    "\n",
    "\n",
    "for epoch in range(0,300):\n",
    "    train(net, epoch)\n",
    "    test(net, epoch)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 방식으로 net2, net3로 학습해 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = resnext101_32x8d().to(device)\n",
    "optimizer = torch.optim.AdamW(net2.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 230, 265], gamma=0.1)\n",
    "\n",
    "for epoch in range(0,300):\n",
    "    train(net2, epoch)\n",
    "    test(net2, epoch)\n",
    "\n",
    "net3 = resnext101_32x8d().to(device)\n",
    "optimizer = torch.optim.AdamW(net3.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 230, 265], gamma=0.1)\n",
    "\n",
    "for epoch in range(0,300):\n",
    "    train(net3, epoch)\n",
    "    test(net3, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종 submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = EMNIST_test(transform = albumentations_transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for img, letter in tqdm(testloader):\n",
    "        img = img.to(device)\n",
    "        letter = letter.to(device)\n",
    "        outputs = net(img, letter)\n",
    "        outputs2 = net2(img, letter)\n",
    "        outputs3 = net3(img, letter)\n",
    "        \n",
    "        y_pred.append(torch.argmax(outputs+outputs2+outputs3, dim=1))\n",
    "\n",
    "import pandas as pd\n",
    "submission = pd.read_csv('submission.csv')\n",
    "submission.digit = torch.cat(y_pred).detach().cpu().numpy()\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기타 \n",
    "초반에만 대회를 진행한터라 순위권을 생각 못하고 있어서 코드를 지저분하게 썼었습니다.  \n",
    "주피터 파일로 코드를 다시 정리해서 올리는 점 이해부탁드립니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본래는  net, net2, net3를 각각 하나씩 따로 코드를 짜서 제출한 형태이고 스코어가 괜찮아서   \n",
    "checkpoint를 load하여 앙상블을 진행했하였습니다.  \n",
    "하지만  하나의 ipynb 파일로 올리기 위해 net2와 net3로 이어서 바로 학습하는 형식으로 일부 코드를 수정하였습니다.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
