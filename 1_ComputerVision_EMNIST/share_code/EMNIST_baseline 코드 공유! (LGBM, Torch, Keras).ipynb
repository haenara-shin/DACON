{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "submission = pd.read_csv('./data/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 구성\n",
    "- 본 문제의 목표는 기존의 MNIST와 다르게,\n",
    "- **문자 속에 숨어있는 숫자를 예측**하는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit</th>\n",
       "      <th>letter</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    digit letter  0  1  2  3  4  5  6  7  ...  774  775  776  777  778  779  \\\n",
       "id                                        ...                                 \n",
       "1       5      L  1  1  1  4  3  0  0  4  ...    2    1    0    1    2    4   \n",
       "2       0      B  0  4  0  0  4  1  1  1  ...    0    3    0    1    4    1   \n",
       "3       4      L  1  1  2  2  1  1  1  0  ...    3    3    3    0    2    0   \n",
       "4       9      D  1  2  0  2  0  4  0  3  ...    3    3    2    0    1    4   \n",
       "5       6      A  3  0  2  4  0  3  0  4  ...    4    4    3    2    1    3   \n",
       "\n",
       "    780  781  782  783  \n",
       "id                      \n",
       "1     4    4    3    4  \n",
       "2     4    2    1    2  \n",
       "3     3    0    2    2  \n",
       "4     0    0    1    1  \n",
       "5     4    3    1    2  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.set_index('id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 787)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train은 digit, letter, 0~783(pixels)의 총 786개의 column과 2,048개의 instance로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>K</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     letter  0  1  2  3  4  5  6  7  8  ...  774  775  776  777  778  779  \\\n",
       "id                                      ...                                 \n",
       "2049      L  0  4  0  2  4  2  3  1  0  ...    2    0    4    2    2    4   \n",
       "2050      C  4  1  4  0  1  1  0  2  2  ...    0    3    2    4    2    4   \n",
       "2051      S  0  4  0  1  3  2  3  0  2  ...    1    3    2    0    3    2   \n",
       "2052      K  2  1  3  3  3  4  3  0  0  ...    3    0    3    2    4    1   \n",
       "2053      W  1  0  1  1  2  2  1  4  1  ...    4    3    1    4    0    2   \n",
       "\n",
       "      780  781  782  783  \n",
       "id                        \n",
       "2049    3    4    1    4  \n",
       "2050    2    2    1    2  \n",
       "2051    3    0    1    4  \n",
       "2052    0    4    4    4  \n",
       "2053    1    2    3    4  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.set_index('id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20480, 786)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test은 letter, 0~783(pixels)의 총 785개의 column과 2,048개의 instance로 구성\n",
    "- `digit`이 우리가 예측하고자 하는 target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEKCAYAAADUyyOuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWn0lEQVR4nO3de4xc9XUH8O93X16vX6wfuxjbrUnqJDzSmGpDSUgRNClxqFSgJVGQElE1rakUqqRKqyBaKahVVdSQl8ijcooVB6WkUQOFqrQ83ERumghYwMEGF2zA2MaLbWyD7bX3NXP6x06ixezvnGXu7NxJft+PZO16zt57f3tnzt7ZPff8fjQziMgvv7ayByAizaFkF8mEkl0kE0p2kUwo2UUyoWQXyYSSXVwkV5A8QdJIzi97PFI/JbtEPg/gRNmDkOKU7JJE8rcArANwa9ljkeI6yh6AtCaS7QBuA/A3AF4teTjSALqyS8qfAugG8LWyByKNoSu7vAHJJQD+FsDHzGycZNlDkgbQlV2m83cAHjaz+8oeiDSOruzyOiTPA/BHAC4heUbt4Z7ax0UkK2Z2qpzRSRFKdjndGgCdAH4yTWwfgNsB/HFTRyQNQfWzy1QklwI4/7SH1wH4LIArADxvZs80fWBSmK7s8jpm9gqAH059jOTq2qf/Y2a6weYXlP5AJ5IJvY0XyYSu7CKZULKLZELJLpIJJbtIJppaeuviHOvmvNnZeZl/Z4zuHS/6R9Ait6bn/PfXQrf0z/Jz6h66/mOPYBhjNjrtDgolO8l1AL4CoB3AP5nZLd7Xd3MeLur4YJFDJtnEhP8Fbe0FD1BNhtjR6W9aqRQ6NNvqf9WGx2bw5s75vmfE2381GFv0nAVjY3uB5zw4LzYx7m8f/TBwEjp8PTnHfrj6UDJW99v4Wr/z1wB8CMC5AK4leW69+xOR2VXkd/YLAewys+fNbAzAdwFc2ZhhiUijFUn2FQD2Tvn/vtpjr0NyPclBkoPjNlrgcCJSRJFkn+6Xjjf8omJmG8xswMwGOjmnwOFEpIgiyb4PwKop/18JYH+x4YjIbCmS7I8CWEPybJJdAD4K4N7GDEtEGq3u0puZTZC8AcD9mCy9bTSzp/yNAKs6JYmozBOVidxjF9u3Vw4JyzBFxo0ZlBW9umxUArKC5a+IV16L6slRaS5Q6LWG4NjReQ3Om1cWjF5PbknRGVahOnttjjLNUybyC0C3y4pkQskukgklu0gmlOwimVCyi2RCyS6SidaaSjrsEfbaTGf3WynUphrUi9nZ5W8ftLgWGVt03qIafzT29r6l6X0vnO8fe66/77bXhv3tj6dnva4cPuJuG7fXBs9p0F7r1dLDbd37B9IhXdlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXyURzS2+kX1YoMouqV44ACrdLzqqC7bcd/UuSscrRV+sZ0c+1v3W1Gz92fvrYAHD0bennu+pPogrr8J9TVnvd+Pw96e37HtybjAHAxEtDbjxszw24La5BKdWdfbaaHpeu7CKZULKLZELJLpIJJbtIJpTsIplQsotkQskukonm1tnNirVjOnX4cMXOqG0wqm06xy68gmxQR69e6K+XOfTunmSs/5GgDbTdP/aLvz3XjY8tiqZkLrgKrKfNr8O/2uPVwlc5MaBvs19Hr+w/4MYj7ustWkHW29ZpE9eVXSQTSnaRTCjZRTKhZBfJhJJdJBNKdpFMKNlFMtHkfvZi9epwlV332H7dNKzTe6I6etBL7023DAB7L0nX0QFgpC99YibmznO3rXS7YYz1BvcfTNTf191WYFsAqMzx6+xVpx/+6Dn+sU/2+3X4qE6/8u9/7Ma9KbwLTd/t9LMXSnaSuwEcx+Ri1hNmNlBkfyIyexpxZb/MzF5pwH5EZBbpd3aRTBRNdgPwAMnHSK6f7gtIric5SHJw3EYLHk5E6lX0bfzFZrafZB+AB0n+n5ltmfoFZrYBwAYAWNi2OFrMTURmSaEru5ntr308COBuABc2YlAi0nh1JzvJeSQX/OxzAJcD2N6ogYlIYxV5G98P4G5O1q87APyzmf1XQ0aVEtWzHV59v/YFbthbYjdcajqo8duiBW58fJG/f2tPx0eWBTcnBD/u20eCOetP+N/b3IPpsfXuHHO3nZjrP99H3+6/fIdXpb/3aod/Xt57lX/deujpd7jxiFdLj5bBtnHnvDmvxbqT3cyeB/CuercXkeZS6U0kE0p2kUwo2UUyoWQXyYSSXSQTTZ5KuljJwetxjaaCtmrwc63ql4E8XrsiAEy879fd+P5Pjbjx7639shu/5ifXJ2P2ctDDGlTm+h/xv2DhtsP+Dg4fTYYqR/zlpLu6/DWduw+uceMv/m66pHnuZTvdbb+68odu/OqTi9z4yOV+A2jXD55MB4Nebvf15nTH6soukgklu0gmlOwimVCyi2RCyS6SCSW7SCaU7CKZaP5U0l6NMKgvWtVp9QxaVAvz2muDY++5fI4b/8DKp934eV3+09TdnW6/PUW/zr7oGb9FdcH9T7nxyvHjbtxr72WHX0evjjltxQD4xDNu/Kwz0vc3dLy/2FLSh4bnu/Flu9P3FwBAtcC86G4eOCFd2UUyoWQXyYSSXSQTSnaRTCjZRTKhZBfJhJJdJBMt1c8e8mq20ZLL0VTR0bGduuiB63/T3XTx2oNu/M+W/bcbH6r4Ndnhw+klnRfu8b/vvodfc+M24i/ZFfXye8+3Oz03ED9nwRwG4/PTr4lr+gbdbUfMf52eOOXfO9H1Ln+Z7UUd6bFVdvi99vXeU6Iru0gmlOwimVCyi2RCyS6SCSW7SCaU7CKZULKLZKK5dXbA7QuPllV2a7Zejy8AWLGa7v6/fE8yNnyeP+/7xrff5cbP6vC/79uO+HOQtx137jEITktlvj9Xf9dZ/f4OIl5PenRvRKC62F/q+qXL0rG1c/a72/7j0bVufOSYX2c/+G7/9dQ+fkYy1vNsgfPi3JIRXtlJbiR5kOT2KY8tJvkgyZ21j731j05EmmEmb+O/BWDdaY/dCGCzma0BsLn2fxFpYWGym9kWAEdOe/hKAJtqn28CcFWDxyUiDVbvH+j6zWwIAGof+1JfSHI9yUGSg+Pw77MWkdkz63+NN7MNZjZgZgOd8P+oISKzp95kP0ByOQDUPvptXSJSunqT/V4A19U+vw7APY0ZjojMlrDOTvJOAJcCWEpyH4DPAbgFwPdIfgLAHgAfnvERvTXWJ/yisNs7HfU+j/u9z3v/2u9Jr74zPT/6je/c7G47MOekG9907G1ufOMT73XjXpX+xGq/F35kmT+vfNv4Kjcere/u8m8vQGWO/3pYcoH/hvLms7+fjHXT3/eGre9z4xz2a+EMzkv3wfr/fuX28TvfVpjsZnZtIvT+aFsRaR26XVYkE0p2kUwo2UUyoWQXyYSSXSQTzV+y2WlrjKaZ9uLs9Fs13SWXAYwu8Wsl71m5Nxn72ILd7rYnzS/7/e/RX3PjbR1+majalY5zwq9vjS8MakTVoD4WoFcl6vS/r8ve7S8XfeuKB9x4b3t6Oueto8Fy0Sf91Ggf88/Lwl1uGB070y22lahdu066sotkQskukgklu0gmlOwimVCyi2RCyS6SCSW7SCaav2RzsMyux2txDffrtNYCgAW17Hkd6ZbEnja/xt8DP37Lqn934/uXz3XjX325/gbEY+N+i+v23We5cRvz718w57TOXzbsbvvBxdvc+HDwnHZW01N833bgA+627cf81FgUrKrc/58vuvHKq+mlsqPlx22ivr5iXdlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXyYSSXSQTrdXPHtTKC/WzW7Ac9By/dnnOvKFk7LnxE+62lWDO5BHzn4avH3DWHgbw0vCiZGx5zzF32zO6/Gmul/e/6sZ7u0+58Z6OsWTsuaNL3G1vevT33fjZZ77ixj//ln9NxpbO8Z8znOUvw922w78/4fjASjfe8x/pabCL3Ivi0ZVdJBNKdpFMKNlFMqFkF8mEkl0kE0p2kUwo2UUy0dw6e8RrfkaxfvY9wZLMqPhz1t+174Jk7KuHL/X3HdX4D81x42f+2N89nXnGd/SvcLc91Rft248fmus/ZxM96R2wEsxJH4RPLPbvrehvH0/Gblr2E3fbp1Ysd+PPrTzbjS+5Y6sb95ddDuaNZ31z+YdXdpIbSR4kuX3KYzeTfInk1tq/K+o6uog0zUzexn8LwLppHv+Sma2t/buvscMSkUYLk93MtgA40oSxiMgsKvIHuhtIPll7m9+b+iKS60kOkhwct/Q8biIyu+pN9m8AeCuAtQCGAHwh9YVmtsHMBsxsoJP+H6JEZPbUlexmdsDMKmZWBfBNABc2dlgi0mh1JTvJqXWJqwFsT32tiLSGsM5O8k4AlwJYSnIfgM8BuJTkWgAGYDeA62d0tGje+KB+GK3f7ln9b/7fGF/4g8VufN9ofzLmrUE+Gfe/r5Vb/B30bPZ/llZPpnvS57lbIly3HtXomwtqvk7N2LtvAgD2/YX/hvFAx1I3/ucLfy8Zqwb3PrzwgF9Hf8sde9x4JZjT3hOdl3r73cNkN7Nrp3n49rqOJiKl0e2yIplQsotkQskukgklu0gmlOwimWitFtcCoqmk2074UwODQXutE26b8Ms40fK+8x7Z7cYrp/zpmsPymScorYVloKAc+twXLnI2djfFnKAjo/NV/1r1yONr6t727Af8KbgrQy+78RALXGejFtgEXdlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXyYSSXSQTza+ze/XFqJ3SqSez3f+5dexd6RZVABifH9QunXD7Kb/O3rclvTwvAFQOHfaPHdRk2eYcP9jWglZMc6apntx/0JbsHL5t1N92dEkwtqC71tv/sp/6++b2Xf6x/UPHdXRLT3NtUQerd869+0GC3YrILwklu0gmlOwimVCyi2RCyS6SCSW7SCaU7CKZ+IXqZ/fqyW3L/Tr6kXf4Pd/WEfR1Oz3rcw+4mwJDfp097CkPevVtIl2zjfr0QwWmRAYA60wfv/24XygfDxYQ8mr4ANDl9KwvfNJ/0qoFpi2fkQL97O59Faqzi4iSXSQTSnaRTCjZRTKhZBfJhJJdJBNKdpFMzGTJ5lUAvg3gTABVABvM7CskFwP4FwCrMbls80fM7GiwM7DdqXd7Mfg968Pn9rnbjvUWqzd3nkjXNvsf8ecY95ZUnolwid4icwREgjnpd355wN+8dywZmxgJCumBNuf2AgDoOeA85y8fcreN+vjdWjfqX1YZgJ8jCO6rKFhnnwDwGTM7B8BFAD5J8lwANwLYbGZrAGyu/V9EWlSY7GY2ZGaP1z4/DmAHgBUArgSwqfZlmwBcNVuDFJHi3tTv7CRXA7gAwMMA+s1sCJj8gQDAfx8tIqWa8b3xJOcD+D6AT5vZMQZzj03Zbj2A9QDQjZ56xigiDTCjKzvJTkwm+nfM7K7awwdILq/FlwOYttvDzDaY2YCZDXSyuxFjFpE6hMnOyUv47QB2mNkXp4TuBXBd7fPrANzT+OGJSKPM5G38xQA+DmAbya21x24CcAuA75H8BIA9AD4c7snMLUlE5Qy0pYc7coZfrqh2+KWUtlH/596yJ5xWz23+msxhGSZacjloM2VHZzoYlXGisQWlu7Zx/zmb2zOajJ1s80tvYQvra8Fz9li6JFodTY8LmEH5Kzhv4WvZKZeG+/bG5rzMw2Q3sx8BSI38/dH2ItIadAedSCaU7CKZULKLZELJLpIJJbtIJpTsIplo7lTSQYtrVF9s71uajB3/lWBp4na/Vt39il8XXbAtPR10tUhdFIAF0xaHU0l79y4Exy7aAjt/t3/eR187Ix3s9Z+T9mBJ5yXbg/P+9PPJWLgU9Syz8XTrb7gMtvdtayppEVGyi2RCyS6SCSW7SCaU7CKZULKLZELJLpKJ5tbZzdxpcKOa8PA56WWZR5f4Ndto2uHeZ/yabXXv/nSwwPK7k9sHdVVv6mD45y3sje4o9hI4635/6eMXr0k/ZwxWg164y48v+tFuN14ZS9eyi0z1DARzCCCoowPxHAazQFd2kUwo2UUyoWQXyYSSXSQTSnaRTCjZRTKhZBfJRHPr7ABg9fcRV7vS9WhW/Fq1t+QyACx6wqmjA6g4/c9hHTyoyUbxaN54r87PNn/bqJc+ugcAh4644QV7liVjPUP+vvse2uvGJ172a/zePADsCOY/iOrk0XMS8eYRiM55nfd16Moukgklu0gmlOwimVCyi2RCyS6SCSW7SCaU7CKZCOvsJFcB+DaAMwFUAWwws6+QvBnAnwA4VPvSm8zsvvCITg0xmst7/q7XkrEz25z5yQF0Dgf96ocOu3Gvrhr2NheswxdRuI4eqLyWXgMdAHrveSp96Hb/WjNx7IQbj3rx3Vp51E8exaNad3BeC81B4K397pT/Z3JTzQSAz5jZ4yQXAHiM5IO12JfM7NYZ7ENEShYmu5kNARiqfX6c5A4AK2Z7YCLSWG/qd3aSqwFcAODh2kM3kHyS5EaSvYlt1pMcJDk4jtFCgxWR+s042UnOB/B9AJ82s2MAvgHgrQDWYvLK/4XptjOzDWY2YGYDnZjTgCGLSD1mlOwkOzGZ6N8xs7sAwMwOmFnFzKoAvgngwtkbpogUFSY7SQK4HcAOM/vilMeXT/myqwFsb/zwRKRRZvLX+IsBfBzANpJba4/dBOBakmsxuUjsbgDXz+iITosr2/1yRfXZF5Kxec8Ghw3KGYUaFi2Yp3qWuaW9gqW1SLgc9alTyVi01HVU3gqng/bKZ8FS1UWn2I5Lc06cQRu4u+/08z2Tv8b/KLGHuKYuIi1Dd9CJZELJLpIJJbtIJpTsIplQsotkQskukonmTyXttbjOcjtmId50zUWngi5wbACgV+qOatXRlMlFecc3//mO7ruwanCtcmrp3jTTQNyWDER1+vqXdA5bd737C5z7WHRlF8mEkl0kE0p2kUwo2UUyoWQXyYSSXSQTSnaRTNAKLKH8pg9GHgLw4pSHlgJ4pWkDeHNadWytOi5AY6tXI8f2q2Y27TrZTU32NxycHDSzgdIG4GjVsbXquACNrV7NGpvexotkQskukomyk31Dycf3tOrYWnVcgMZWr6aMrdTf2UWkecq+sotIkyjZRTJRSrKTXEfyGZK7SN5YxhhSSO4muY3kVpKDJY9lI8mDJLdPeWwxyQdJ7qx9nHaNvZLGdjPJl2rnbivJK0oa2yqSPyC5g+RTJD9Ve7zUc+eMqynnrem/s5NsB/AsgN8BsA/AowCuNbOnmzqQBJK7AQyYWek3YJC8BMAJAN82s/Nrj/0DgCNmdkvtB2WvmX22RcZ2M4ATZS/jXVutaPnUZcYBXAXgD1HiuXPG9RE04byVcWW/EMAuM3vezMYAfBfAlSWMo+WZ2RYAR057+EoAm2qfb8Lki6XpEmNrCWY2ZGaP1z4/DuBny4yXeu6ccTVFGcm+AsDeKf/fh9Za790APEDyMZLryx7MNPrNbAiYfPEA6Ct5PKcLl/FuptOWGW+Zc1fP8udFlZHs000s1kr1v4vN7DcAfAjAJ2tvV2VmZrSMd7NMs8x4S6h3+fOiykj2fQBWTfn/SgD7SxjHtMxsf+3jQQB3o/WWoj7wsxV0ax8Pljyen2ulZbynW2YcLXDuylz+vIxkfxTAGpJnk+wC8FEA95YwjjcgOa/2hxOQnAfgcrTeUtT3Ariu9vl1AO4pcSyv0yrLeKeWGUfJ56705c/NrOn/AFyByb/IPwfgr8oYQ2JcbwHw09q/p8oeG4A7Mfm2bhyT74g+AWAJgM0AdtY+Lm6hsd0BYBuAJzGZWMtLGtv7MPmr4ZMAttb+XVH2uXPG1ZTzpttlRTKhO+hEMqFkF8mEkl0kE0p2kUwo2UUyoWQXyYSSXSQT/w9thzripELK4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Image는 어떻게 생겼을까?\n",
    "img = train.query(\"letter == 'A'\")[\n",
    "        [(str(i)) for i in range(784)]\n",
    "    ].iloc[28].values.reshape(28, 28)\n",
    "plt.imshow(img)\n",
    "plt.title(train.query(\"letter == 'A'\").iloc[i]['digit'], fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        774\n",
       "digit       4\n",
       "letter      A\n",
       "Name: 773, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.query(\"letter == 'A'\").iloc[28].iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 이미지는 `A` 문자 속에 `4`가 숨이있다!\n",
    "- 모든 이미지들은 위와 같이 생겼음.\n",
    "- 4를 예측하는 것이 우리의 목표."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN을 사용해보자!\n",
    "- CNN은 영상 처리 기법을 DEEP LEARNING으로 구현한 것(이라고 저는 이해)\n",
    "- 아래 커널을 이미지마다 적용, Convolution 연산(가중합)을 취해 이미지의 특성을 파악하는 것이 목적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1947d53b390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이런 식으로 특성을 파악하는 것이 목적이다.\n",
    "\n",
    "kernel = np.array(\n",
    "    [\n",
    "        [0, -100, 0],\n",
    "        [0, 255, 0],\n",
    "        [0, -100, 0],\n",
    "    ]\n",
    ")\n",
    "plt.imshow(correlate2d(img, kernel, mode='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 구축\n",
    "\n",
    "- `LightGBM`\n",
    "- `PyTorch - CNN`\n",
    "- `Keras - CNN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자 데이터를 one-hot encoding하고\n",
    "# 이미지 픽셀 데이터를 784개의 위치 feature라고 생각하고 concat\n",
    "X_train = pd.concat(\n",
    "    (pd.get_dummies(train.letter), train[[str(i) for i in range(784)]]), \n",
    "    axis=1)\n",
    "y_train = train['digit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D  E  F  G  H  I  J  ...  774  775  776  777  778  779  780  781  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...    2    1    0    1    2    4    4    4   \n",
       "1  0  1  0  0  0  0  0  0  0  0  ...    0    3    0    1    4    1    4    2   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...    3    3    3    0    2    0    3    0   \n",
       "3  0  0  0  1  0  0  0  0  0  0  ...    3    3    2    0    1    4    0    0   \n",
       "4  1  0  0  0  0  0  0  0  0  0  ...    4    4    3    2    1    3    4    3   \n",
       "\n",
       "   782  783  \n",
       "0    3    4  \n",
       "1    1    2  \n",
       "2    2    2  \n",
       "3    1    1  \n",
       "4    1    2  \n",
       "\n",
       "[5 rows x 810 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       0\n",
       "2       4\n",
       "3       9\n",
       "4       6\n",
       "       ..\n",
       "2043    6\n",
       "2044    1\n",
       "2045    9\n",
       "2046    0\n",
       "2047    5\n",
       "Name: digit, Length: 2048, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set을 8:2로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier(device='gpu') # GPU를 쓰려면 따로 설치해줘야 함.\n",
    "# http://www.kwangsiklee.com/2018/05/lightgbm-사용시-gpu-가속하기/\n",
    "# 위의 링크 참고할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               device='gpu', importance_type='split', learning_rate=0.1,\n",
       "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 적합\n",
    "lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5536585365853659\n"
     ]
    }
   ],
   "source": [
    "# 예측 정확도 출력\n",
    "print((lgb.predict(X_valid) == y_valid.values).sum() / len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터에 대해 예측을 진행\n",
    "X_test = pd.concat(\n",
    "    (pd.get_dummies(test.letter), test[[str(i) for i in range(784)]]), \n",
    "axis=1)\n",
    "\n",
    "# Submission 컬럼에 이를 기록\n",
    "submission.digit = lgb.predict(X_test)\n",
    "\n",
    "# 파일로 저장 후 업로드\n",
    "submission.to_csv('first_submission.csv', index=False) # 57.84313725% 의 결과를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch - CNN\n",
    "- 입력 이미지의 shape을 `(batch_size, n_channels, width, height)`로 넣어줘야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자는 one-hot encoding한 후에 (-1, 1, 26)으로 reshape\n",
    "# pixel값들도 (-1, 1, 784)로 reshape\n",
    "# 그 후 concat하여 (2048, 1, 810)으로 X_train 구축\n",
    "X_train = np.concatenate(\n",
    "    [\n",
    "        pd.get_dummies(train.letter).values.reshape(-1, 1, 26),\n",
    "        (train[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 1, 784)\n",
    "    ], \n",
    "    axis=2\n",
    ")\n",
    "# Label Setting\n",
    "y_train = train['digit'].values\n",
    "\n",
    "# Train-Test를 8:2로 분할\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1638, 1, 810), (410, 1, 810), (1638,), (410,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch.Tensor로 형변환\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_valid = torch.Tensor(X_valid)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_valid = torch.LongTensor(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import (\n",
    "    TensorDataset, \n",
    "    DataLoader, \n",
    "    RandomSampler, \n",
    "    SequentialSampler\n",
    ")\n",
    "\n",
    "\n",
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "train_data = TensorDataset(\n",
    "    X_train[:, :, :26], # Letter\n",
    "    X_train[:, :, 26:].reshape(-1, 1, 28, 28), # Image (28, 28)\n",
    "    y_train # Label\n",
    ")\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(\n",
    "    X_valid[:, :, :26], # Letter\n",
    "    X_valid[:, :, 26:].reshape(-1, 1, 28, 28), # Image (28, 28)\n",
    "    y_valid # Label\n",
    ")\n",
    "validation_sampler = SequentialSampler(\n",
    "    validation_data)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Construct\n",
    "\n",
    "class ConvClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Letter를 처리할 1D Conv Block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(16, 64, 4, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 5, padding=2), nn.ReLU(),\n",
    "            nn.Conv1d(128, 64, 4, padding=2), nn.ReLU(),\n",
    "            nn.Conv1d(64, 16, 3), nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Image를 처리할 2D Conv Block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 128, 5, padding=2), nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 7, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, 9, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(512, 256, 9, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(256, 128, 7, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, 7, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, 5, padding=3), nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # 위 두 블럭을 지나 concat후 Fully Connected를 지나\n",
    "        # label을 예측\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(22016, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "        \n",
    "        # 다중 Label이므로 Cross Entropy Loss를 정의\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x1, x2, label=False):\n",
    "        out = self._inference(x1, x2)\n",
    "        if label is not False:\n",
    "            # label이 입력으로 들어오면 loss도 계산해서 return\n",
    "            loss = self.loss(out, label)\n",
    "            return (out, loss)\n",
    "        # label이 입력되지 않으면 ``self._inference``와 동일.\n",
    "        return out\n",
    "    \n",
    "    def _inference(self, x1, x2):\n",
    "        bsz = x1.size(0)\n",
    "        \n",
    "        x1 = self.conv1(x1)\n",
    "        x2 = self.conv2(x2)\n",
    "        \n",
    "        x1 = x1.view(bsz, -1)\n",
    "        x2 = x2.view(bsz, -1)\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "#         return x\n",
    "        out = F.softmax(self.out(x), dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvClassifier(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(16, 64, kernel_size=(4,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "    (4): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (5): ReLU()\n",
       "    (6): Conv1d(128, 64, kernel_size=(4,), stride=(1,), padding=(2,))\n",
       "    (7): ReLU()\n",
       "    (8): Conv1d(64, 16, kernel_size=(3,), stride=(1,))\n",
       "    (9): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(128, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(256, 512, kernel_size=(9, 9), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(512, 256, kernel_size=(9, 9), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(3, 3))\n",
       "    (15): ReLU()\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=22016, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 구축\n",
    "model = ConvClassifier()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력이 제대로 들어갈 지 확인\n",
    "x1 = X_train[:32, :, :26].cuda()\n",
    "x2 = X_train[:32, :, 26:].reshape(-1, 1, 28, 28).cuda()\n",
    "\n",
    "model(x1, x2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = Adam(\n",
    "    model.parameters(),\n",
    "    lr=2e-5, # 학습률\n",
    "    eps=1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    ")\n",
    "\n",
    "# 에폭수\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 150/150] Avg Training Loss: 1.54 Valid Acc: 0.69\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 반복\n",
    "history = defaultdict(list)\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        x1, x2, label = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = model(x1, x2, label)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[1]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "        history['train_loss'].append(loss.item())\n",
    "        \n",
    "        # 정확도 계산\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        label = label.to('cpu').numpy()\n",
    "        tmp_train_accuracy = flat_accuracy(logits, label)\n",
    "        history['train_acc'].append(tmp_train_accuracy)\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        x1, x2, label = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(x1, x2, label)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "        history['eval_loss'].append(outputs[1].item())\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label = label.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label)\n",
    "        history['eval_acc'].append(tmp_eval_accuracy)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    s = f'\\r[Epoch {epoch_i+1}/{epochs}]'\n",
    "    s += f' Avg Training Loss: {avg_train_loss:.2f}'\n",
    "    s += \" Valid Acc: {0:.2f}\".format(eval_accuracy/nb_eval_steps)\n",
    "    print(s, end='')\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 parameter를 저장\n",
    "torch.save(model.state_dict(), 'convclf200803.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvClassifier(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(16, 64, kernel_size=(4,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "    (4): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (5): ReLU()\n",
       "    (6): Conv1d(128, 64, kernel_size=(4,), stride=(1,), padding=(2,))\n",
       "    (7): ReLU()\n",
       "    (8): Conv1d(64, 16, kernel_size=(3,), stride=(1,))\n",
       "    (9): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(128, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(256, 512, kernel_size=(9, 9), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(512, 256, kernel_size=(9, 9), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(3, 3))\n",
       "    (15): ReLU()\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=22016, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 로드하여 test를 진행할 것임\n",
    "model = ConvClassifier()\n",
    "model.load_state_dict(torch.load('convclf200803.pt'))\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test셋 전처리\n",
    "X_test = np.concatenate(\n",
    "    [\n",
    "        pd.get_dummies(test.letter).values.reshape(-1, 1, 26),\n",
    "        (test[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 1, 784)\n",
    "    ], \n",
    "    axis=2\n",
    ")\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "\n",
    "x1 = X_test[:, :, :26].cuda()\n",
    "x2 = X_test[:, :, 26:].reshape(-1, 1, 28, 28).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "test_data = TensorDataset(x1, x2)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 예측 실시\n",
    "y_pred = []\n",
    "for batch in test_dataloader:\n",
    "    input1, input2 = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input1, input2)\n",
    "    y_pred.append(torch.argmax(outputs, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.digit = torch.cat(y_pred).detach().cpu().numpy()\n",
    "\n",
    "submission.to_csv('second_submission.csv', index=False) # 0.6960784314%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras - CNN\n",
    "- 입력 이미지의 shape을 `(batch_size, width, height, n_channels)`로 넣어줘야 함.\n",
    "- Keras 모델과 Torch 모델을 한 노트북에서 돌릴 경우, GPU할당 문제로 오류가 뜸.\n",
    "- 아래 코드를 다른 노트북에 옮겨서 새롭게 라이브러리, 데이터를 호출 후 진행 바람."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout, MaxPool2D,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add\n",
    ")\n",
    "\n",
    "# LOAD LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# How to check if Keras is using GPU?\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "submission = pd.read_csv('./data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (train[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 28, 28, 1)\n",
    "y_train = to_categorical(train['digit'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아마 성능 향상의 가장 큰 요인, 데이터 증강\n",
    "# CREATE MORE IMAGES VIA DATA AUGMENTATION\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.10,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 128)         131200    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 325,578\n",
      "Trainable params: 325,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECREASE LEARNING RATE EACH EPOCH\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN: Epochs=45, Train accuracy=0.78355, Validation accuracy=0.78049\n"
     ]
    }
   ],
   "source": [
    "epochs = 45\n",
    "# Train-Test를 9:1로 분리\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(\n",
    "    X_train, y_train, test_size = 0.1)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(X_train2, y_train2, batch_size=32),\n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=X_train2.shape[0]//32,\n",
    "    validation_data=(X_val2, y_val2), \n",
    "    callbacks=[annealer], \n",
    "    verbose=0\n",
    ")\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['acc']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_acc']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter 및 모델 구조 저장\n",
    "model.save_weights(f'params.h5')\n",
    "    \n",
    "model_json = model.to_json()\n",
    "with open(f\"model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 진행\n",
    "X_test = (test[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 28, 28, 1)\n",
    "results = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.digit = results\n",
    "submission.to_csv('1234.csv', index=False) # 0.795575446%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결론\n",
    "- 여러 아이디어가 있었으나, 일단 딥러닝은 깊게 쌓고 많이 돌려봐야 과적합인지 과소적합인지가 나오는 듯.\n",
    "- 많이 쌓고 연산 돌려봅시다.\n",
    "- 구조에 대한 이해도가 필요할 듯\n",
    "- 의외로 LeakyReLU냐 그냥 ReLU냐에 따른 성능 차이도 존재\n",
    "- skip-connection 등 여러 개념을 적용하며 성능을 높여보자!\n",
    "- letter의 정보를 적극적으로 활용할 방안이 있을까?\n",
    "- 어지간하면 keras쓰자. torch로 짜기엔 너무 할게 많...\n",
    "- 그리고 성능도 keras가 우리같은 입문자에겐 더 좋다. 이미 성능이 좋기로 알려진 초기화 기법들, 과적합 방지 기술들이 잘 구현되어 있다!!\n",
    "- Learning Rate 조절도 신경써서 해보자!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
